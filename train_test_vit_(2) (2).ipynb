{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RbkjpUJ4xYv"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "mwWILR-c8_d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mBmhata6-mMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "rNFAFiwG9PhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "AMuukglf9ebF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device # select gpu from edit -> notebook settings ->gpu"
      ],
      "metadata": {
        "id": "f8D6tsay9j1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory paths to train and test images\n",
        "train_dir = 'AI_demos/custom_dataset/train'\n",
        "test_dir = 'AI_demos/custom_dataset/test'"
      ],
      "metadata": {
        "id": "I8Bm7S8A9pNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create Datasets and DataLoaders\n",
        "\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  # Use ImageFolder to create dataset(s)\n",
        "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "  # Get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn images into data loaders\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "wnHwlUUA99kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Create transform pipeline manually\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "print(f\"Manually created transforms: {manual_transforms}\")"
      ],
      "metadata": {
        "id": "anF40lsw-enC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=manual_transforms,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "fkP7tOFZ-n4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['benign', 'malignant']\n",
        "\n",
        "        # Get all image paths and their filenames\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.filenames = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(class_path, filename))\n",
        "                    self.labels.append(class_idx)\n",
        "                    self.filenames.append(filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, self.filenames[idx]\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create datasets for train and test\n",
        "train_dataset = BreastCancerDataset(data_dir='AI_demos/custom_dataset/train', transform=transform)\n",
        "test_dataset = BreastCancerDataset(data_dir='AI_demos/custom_dataset/test', transform=transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Visualize an image from training set\n",
        "image_batch, label_batch, filename_batch = next(iter(train_dataloader))\n",
        "\n",
        "# Get first image details\n",
        "image = image_batch[0]\n",
        "label = label_batch[0]\n",
        "filename = filename_batch[0]\n",
        "\n",
        "print(f\"Displaying image: {filename}\")\n",
        "print(f\"Label: {'benign' if label == 0 else 'malignant'}\")\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title(f\"Class: {'benign' if label == 0 else 'malignant'}\\nFilename: {filename}\")\n",
        "plt.axis(False)\n",
        "plt.show()\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Training set: {len(train_dataset)} images\")\n",
        "print(f\"Test set: {len(test_dataset)} images\")\n",
        "\n",
        "# Print class distribution in training set\n",
        "train_labels = [label for _, label, _ in train_dataset]\n",
        "benign_count = sum(1 for label in train_labels if label == 0)\n",
        "malignant_count = sum(1 for label in train_labels if label == 1)\n",
        "\n",
        "print(f\"\\nTraining set class distribution:\")\n",
        "print(f\"Benign: {benign_count} images\")\n",
        "print(f\"Malignant: {malignant_count} images\")"
      ],
      "metadata": {
        "id": "-soFCAGaBWs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Breast Cancer Classification System\n",
        "# A comprehensive system for classifying breast cancer images as benign or malignant\n",
        "# using a Vision Transformer (ViT) and CNN ensemble approach\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import logging\n",
        "import datetime\n",
        "\n",
        "# 1. Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 2. Logging Setup\n",
        "def setup_logger(log_filename=None):\n",
        "    \"\"\"Set up logger for training/evaluation\"\"\"\n",
        "    # Create logger\n",
        "    logger = logging.getLogger('BreastCancerClassifier')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Create formatter\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "    # Create console handler\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_handler.setFormatter(formatter)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    # Create file handler if filename is provided\n",
        "    if log_filename:\n",
        "        file_handler = logging.FileHandler(log_filename)\n",
        "        file_handler.setLevel(logging.INFO)\n",
        "        file_handler.setFormatter(formatter)\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "# 3. Dataset Class with Advanced Medical Image Preprocessing\n",
        "class BreastCancerDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform=None, apply_preprocessing=True):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['benign', 'malignant']\n",
        "        self.apply_preprocessing = apply_preprocessing\n",
        "\n",
        "        # Get all image paths and their filenames\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.filenames = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "            for filename in os.listdir(class_path):\n",
        "                if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(class_path, filename))\n",
        "                    self.labels.append(class_idx)\n",
        "                    self.filenames.append(filename)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def apply_advanced_preprocessing(self, img):\n",
        "        \"\"\"Apply advanced preprocessing with better error handling\"\"\"\n",
        "        try:\n",
        "            # Convert to numpy for OpenCV processing\n",
        "            np_img = np.array(img)\n",
        "\n",
        "            # Check for valid image dimensions\n",
        "            if np_img.ndim != 3 or np_img.shape[2] != 3:\n",
        "                print(f\"Warning: Image has unexpected dimensions {np_img.shape}. Skipping advanced preprocessing.\")\n",
        "                return img\n",
        "\n",
        "            try:\n",
        "                # Convert to LAB color space\n",
        "                lab = cv2.cvtColor(np_img, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "                # Apply CLAHE to L channel with stronger parameters\n",
        "                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "                lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
        "\n",
        "                # Convert back to RGB\n",
        "                enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "            except cv2.error as e:\n",
        "                print(f\"OpenCV error during color conversion: {e}. Using original image.\")\n",
        "                return img\n",
        "\n",
        "            try:\n",
        "                # Apply bilateral filter for noise reduction while preserving edges\n",
        "                enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
        "            except Exception as e:\n",
        "                print(f\"Error during bilateral filtering: {e}. Continuing with partial preprocessing.\")\n",
        "\n",
        "            try:\n",
        "                # Apply unsharp masking for edge enhancement\n",
        "                gaussian = cv2.GaussianBlur(enhanced, (0, 0), 3.0)\n",
        "                enhanced = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)\n",
        "            except Exception as e:\n",
        "                print(f\"Error during unsharp masking: {e}. Using partially preprocessed image.\")\n",
        "\n",
        "            return Image.fromarray(enhanced)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error in preprocessing: {e}. Using original image.\")\n",
        "            return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Apply advanced preprocessing for better feature visibility\n",
        "        if self.apply_preprocessing:\n",
        "            try:\n",
        "                image = self.apply_advanced_preprocessing(image)\n",
        "            except Exception as e:\n",
        "                print(f\"Preprocessing error: {e}. Using original image.\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, self.filenames[idx]\n",
        "\n",
        "# 4. Custom Dataset for Split Data\n",
        "class BreastCancerDatasetFromList(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_list, transform=None, apply_preprocessing=True):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.apply_preprocessing = apply_preprocessing\n",
        "        self.classes = ['benign', 'malignant']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def apply_advanced_preprocessing(self, img):\n",
        "        # Same preprocessing as in the main dataset class\n",
        "        try:\n",
        "            # Convert to numpy for OpenCV processing\n",
        "            np_img = np.array(img)\n",
        "\n",
        "            # Check for valid image dimensions\n",
        "            if np_img.ndim != 3 or np_img.shape[2] != 3:\n",
        "                return img\n",
        "\n",
        "            # Convert to LAB color space\n",
        "            lab = cv2.cvtColor(np_img, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "            # Apply CLAHE to L channel with stronger parameters\n",
        "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "            lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
        "\n",
        "            # Convert back to RGB\n",
        "            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "            # Apply bilateral filter for noise reduction while preserving edges\n",
        "            enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
        "\n",
        "            # Apply unsharp masking for edge enhancement\n",
        "            gaussian = cv2.GaussianBlur(enhanced, (0, 0), 3.0)\n",
        "            enhanced = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)\n",
        "\n",
        "            return Image.fromarray(enhanced)\n",
        "        except Exception:\n",
        "            return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path, label = self.file_list[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        filename = os.path.basename(image_path)\n",
        "\n",
        "        # Apply advanced preprocessing\n",
        "        if self.apply_preprocessing:\n",
        "            try:\n",
        "                image = self.apply_advanced_preprocessing(image)\n",
        "            except:\n",
        "                pass  # If enhancement fails, use original image\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, filename\n",
        "\n",
        "# 5. Data Transforms\n",
        "def get_transforms(train=True):\n",
        "    \"\"\"Enhanced specialized transforms for medical imaging\"\"\"\n",
        "    if train:\n",
        "        return transforms.Compose([\n",
        "            # Enhanced standard transforms\n",
        "            transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),  # Wider scale variation\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),  # Medical images don't have fixed orientation\n",
        "            transforms.RandomRotation(90),    # More aggressive rotation\n",
        "            transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # Simulate focus variations\n",
        "            transforms.ColorJitter(brightness=0.3, contrast=0.4, saturation=0.2, hue=0.1),  # More aggressive\n",
        "\n",
        "            # Convert to tensor (must be before tensor-based transforms)\n",
        "            transforms.ToTensor(),\n",
        "\n",
        "            # Tensor-based transforms\n",
        "            transforms.RandomErasing(p=0.4, scale=(0.02, 0.25)),  # More aggressive erasing\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "# 6. Model Architecture: ViT-CNN Ensemble\n",
        "class ViTCNNEnsemble(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ViTCNNEnsemble, self).__init__()\n",
        "\n",
        "        # ViT branch - Use a stronger variant\n",
        "        self.vit = timm.create_model(\n",
        "            'vit_base_patch16_224_dino',  # Stronger ViT model\n",
        "            pretrained=True,\n",
        "            num_classes=0  # Get feature vector only\n",
        "        )\n",
        "\n",
        "        # CNN branch - Use a strong CNN architecture\n",
        "        self.cnn = timm.create_model(\n",
        "            'resnet50d',  # Stronger CNN backbone\n",
        "            pretrained=True,\n",
        "            num_classes=0  # Get feature vector only\n",
        "        )\n",
        "\n",
        "        # Hidden dimension sizes\n",
        "        self.vit_dim = self.vit.embed_dim  # Usually 768 for vit_base\n",
        "        self.cnn_dim = 2048  # ResNet50 feature dim\n",
        "\n",
        "        # Add Stochastic Depth (helps with regularization)\n",
        "        self.vit.drop_path_rate = 0.2\n",
        "\n",
        "        # Feature attention module\n",
        "        self.vit_attention = nn.Sequential(\n",
        "            nn.Linear(self.vit_dim, self.vit_dim),\n",
        "            nn.LayerNorm(self.vit_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.vit_dim, self.vit_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.cnn_attention = nn.Sequential(\n",
        "            nn.Linear(self.cnn_dim, self.cnn_dim),\n",
        "            nn.LayerNorm(self.cnn_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.cnn_dim, self.cnn_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Feature fusion module\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(self.vit_dim + self.cnn_dim, 1024),\n",
        "            nn.LayerNorm(1024),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        # Classification head with strong regularization\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LayerNorm(512),  # Better normalization\n",
        "            nn.GELU(),  # GELU often works better than ReLU with transformers\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features from both branches\n",
        "        vit_features = self.vit(x)\n",
        "        cnn_features = self.cnn(x)\n",
        "\n",
        "        # Apply attention to both feature sets\n",
        "        vit_attention = self.vit_attention(vit_features)\n",
        "        cnn_attention = self.cnn_attention(cnn_features)\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        vit_features = vit_features * vit_attention\n",
        "        cnn_features = cnn_features * cnn_attention\n",
        "\n",
        "        # Concatenate features\n",
        "        combined_features = torch.cat([vit_features, cnn_features], dim=1)\n",
        "\n",
        "        # Apply fusion and classification\n",
        "        fused = self.fusion(combined_features)\n",
        "        out = self.classifier(fused)\n",
        "\n",
        "        return out\n",
        "\n",
        "# 7. Custom loss function: Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', device='cuda'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "        # If alpha is provided, it should be a tensor of class weights\n",
        "        if alpha is not None:\n",
        "            if isinstance(alpha, list) or isinstance(alpha, np.ndarray):\n",
        "                self.alpha = torch.tensor(alpha, dtype=torch.float32).to(device)\n",
        "            else:\n",
        "                self.alpha = alpha\n",
        "        else:\n",
        "            self.alpha = None\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Get standard cross entropy loss\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "\n",
        "        # Get probabilities\n",
        "        pt = torch.exp(-ce_loss)\n",
        "\n",
        "        # Apply focal weighting\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "# 8. Custom Learning Rate Scheduler\n",
        "class WarmupCosineScheduler:\n",
        "    \"\"\"Implements learning rate warmup and cosine decay.\"\"\"\n",
        "    def __init__(self, optimizer, warmup_epochs, total_epochs, min_lr_ratio=0.1):\n",
        "        self.optimizer = optimizer\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.total_epochs = total_epochs\n",
        "        self.min_lr_ratio = min_lr_ratio\n",
        "\n",
        "        # Store base learning rates for each parameter group\n",
        "        self.base_lrs = [param_group['lr'] for param_group in optimizer.param_groups]\n",
        "\n",
        "    def step(self, epoch):\n",
        "        \"\"\"Update learning rate based on current epoch\"\"\"\n",
        "        if epoch < self.warmup_epochs:\n",
        "            # Linear warmup\n",
        "            lr_factor = epoch / self.warmup_epochs\n",
        "        else:\n",
        "            # Cosine annealing\n",
        "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
        "            lr_factor = self.min_lr_ratio + 0.5 * (1 - self.min_lr_ratio) * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "        # Update learning rates for each parameter group\n",
        "        for i, param_group in enumerate(self.optimizer.param_groups):\n",
        "            param_group['lr'] = self.base_lrs[i] * lr_factor\n",
        "\n",
        "# 9. MixUp Data Augmentation\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs and targets'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# 10. Dataset Splitting Function\n",
        "def create_dataset_splits(data_dir, val_split=0.15, test_split=0.15, random_seed=42):\n",
        "    \"\"\"Create train, validation, and test splits\"\"\"\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    classes = ['benign', 'malignant']\n",
        "    train_files = []\n",
        "    val_files = []\n",
        "    test_files = []\n",
        "\n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        all_files = [os.path.join(class_path, f) for f in os.listdir(class_path)\n",
        "                    if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "        # Shuffle files\n",
        "        np.random.shuffle(all_files)\n",
        "\n",
        "        # Calculate split indices\n",
        "        n_files = len(all_files)\n",
        "        n_test = int(test_split * n_files)\n",
        "        n_val = int(val_split * n_files)\n",
        "\n",
        "        # Split files\n",
        "        test_files.extend([(f, class_idx) for f in all_files[:n_test]])\n",
        "        val_files.extend([(f, class_idx) for f in all_files[n_test:n_test+n_val]])\n",
        "        train_files.extend([(f, class_idx) for f in all_files[n_test+n_val:]])\n",
        "\n",
        "    print(f\"Split created: {len(train_files)} training, {len(val_files)} validation, {len(test_files)} test files\")\n",
        "\n",
        "    return train_files, val_files, test_files\n",
        "\n",
        "# 11. DataLoader Creation Functions\n",
        "def create_dataloaders(batch_size=16):\n",
        "    \"\"\"Create dataloaders with class-balanced sampling\"\"\"\n",
        "    # Create datasets with appropriate transforms\n",
        "    train_dataset = BreastCancerDataset(\n",
        "        data_dir='AI_demos/custom_dataset/train',\n",
        "        transform=get_transforms(train=True),\n",
        "        apply_preprocessing=True  # Apply advanced preprocessing\n",
        "    )\n",
        "    test_dataset = BreastCancerDataset(\n",
        "        data_dir='AI_demos/custom_dataset/test',\n",
        "        transform=get_transforms(train=False),\n",
        "        apply_preprocessing=True  # Apply same preprocessing to test\n",
        "    )\n",
        "\n",
        "    # Calculate class weights for weighted sampling\n",
        "    train_labels = torch.tensor([label for _, label, _ in train_dataset])\n",
        "    class_counts = torch.bincount(train_labels)\n",
        "    total_samples = sum(class_counts)\n",
        "\n",
        "    # Calculate inverse weights for more aggressive balancing\n",
        "    inverse_weights = total_samples / (class_counts * len(class_counts))\n",
        "    sample_weights = inverse_weights[train_labels]\n",
        "\n",
        "    # Create sampler for balanced training\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(train_dataset),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=os.cpu_count() or 2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=os.cpu_count() or 2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Get class names\n",
        "    class_names = train_dataset.classes\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names\n",
        "\n",
        "def create_split_dataloaders(data_dir, batch_size=16):\n",
        "    \"\"\"Create dataloaders with separate train/val/test splits\"\"\"\n",
        "    # Create data splits\n",
        "    train_files, val_files, test_files = create_dataset_splits(data_dir)\n",
        "\n",
        "    # Create datasets with appropriate transforms\n",
        "    train_dataset = BreastCancerDatasetFromList(\n",
        "        file_list=train_files,\n",
        "        transform=get_transforms(train=True),\n",
        "        apply_preprocessing=True\n",
        "    )\n",
        "\n",
        "    val_dataset = BreastCancerDatasetFromList(\n",
        "        file_list=val_files,\n",
        "        transform=get_transforms(train=False),\n",
        "        apply_preprocessing=True\n",
        "    )\n",
        "\n",
        "    test_dataset = BreastCancerDatasetFromList(\n",
        "        file_list=test_files,\n",
        "        transform=get_transforms(train=False),\n",
        "        apply_preprocessing=True\n",
        "    )\n",
        "\n",
        "    # Calculate class weights for weighted sampling (train only)\n",
        "    train_labels = [label for _, label, _ in train_dataset]\n",
        "    class_counts = np.bincount(train_labels)\n",
        "    total_samples = sum(class_counts)\n",
        "\n",
        "    # Calculate inverse weights for more aggressive balancing\n",
        "    inverse_weights = total_samples / (class_counts * len(class_counts))\n",
        "    sample_weights = [inverse_weights[label] for label in train_labels]\n",
        "\n",
        "    # Create sampler for balanced training\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(train_dataset),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=os.cpu_count() or 2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=os.cpu_count() or 2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=os.cpu_count() or 2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Get class names\n",
        "    class_names = train_dataset.classes\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, class_names\n",
        "\n",
        "# 12. Parameter Group Creation for Optimizer\n",
        "def get_optimizer_grouped_parameters(model, weight_decay=0.05):\n",
        "    # Track which parameters have been assigned to prevent duplicates\n",
        "    assigned_params = set()\n",
        "    optimizer_grouped_parameters = []\n",
        "\n",
        "    # Define parameter groups with a function to ensure no duplicates\n",
        "    def add_params_to_group(params_list, weight_decay_value, lr_multiplier):\n",
        "        filtered_params = []\n",
        "        for param in params_list:\n",
        "            # Use id(param) to uniquely identify each parameter\n",
        "            param_id = id(param)\n",
        "            if param_id not in assigned_params:\n",
        "                filtered_params.append(param)\n",
        "                assigned_params.add(param_id)\n",
        "\n",
        "        if filtered_params:  # Only add group if it has parameters\n",
        "            optimizer_grouped_parameters.append({\n",
        "                \"params\": filtered_params,\n",
        "                \"weight_decay\": weight_decay_value,\n",
        "                \"lr_mult\": lr_multiplier\n",
        "            })\n",
        "\n",
        "    # No decay for biases and LayerNorm params\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "    # Group parameters by component and whether they should have weight decay\n",
        "    vit_params_decay = [p for n, p in model.named_parameters()\n",
        "                        if not any(nd in n for nd in no_decay) and \"vit\" in n]\n",
        "    vit_params_no_decay = [p for n, p in model.named_parameters()\n",
        "                           if any(nd in n for nd in no_decay) and \"vit\" in n]\n",
        "\n",
        "    cnn_params_decay = [p for n, p in model.named_parameters()\n",
        "                        if not any(nd in n for nd in no_decay) and \"cnn\" in n]\n",
        "    cnn_params_no_decay = [p for n, p in model.named_parameters()\n",
        "                           if any(nd in n for nd in no_decay) and \"cnn\" in n]\n",
        "\n",
        "    attention_params_decay = [p for n, p in model.named_parameters()\n",
        "                              if not any(nd in n for nd in no_decay) and \"attention\" in n]\n",
        "    attention_params_no_decay = [p for n, p in model.named_parameters()\n",
        "                                if any(nd in n for nd in no_decay) and \"attention\" in n]\n",
        "\n",
        "    fusion_classifier_params_decay = [p for n, p in model.named_parameters()\n",
        "                                      if not any(nd in n for nd in no_decay) and (\"fusion\" in n or \"classifier\" in n)]\n",
        "    fusion_classifier_params_no_decay = [p for n, p in model.named_parameters()\n",
        "                                        if any(nd in n for nd in no_decay) and (\"fusion\" in n or \"classifier\" in n)]\n",
        "\n",
        "    # Add parameters to groups in order of priority\n",
        "    add_params_to_group(vit_params_decay, weight_decay, 0.05)\n",
        "    add_params_to_group(vit_params_no_decay, 0.0, 0.05)\n",
        "    add_params_to_group(cnn_params_decay, weight_decay, 0.1)\n",
        "    add_params_to_group(cnn_params_no_decay, 0.0, 0.1)\n",
        "    add_params_to_group(attention_params_decay, weight_decay, 0.3)\n",
        "    add_params_to_group(attention_params_no_decay, 0.0, 0.3)\n",
        "    add_params_to_group(fusion_classifier_params_decay, weight_decay, 1.0)\n",
        "    add_params_to_group(fusion_classifier_params_no_decay, 0.0, 1.0)\n",
        "\n",
        "    return optimizer_grouped_parameters\n",
        "\n",
        "# 13. Model Checkpointing\n",
        "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, val_acc, filename):\n",
        "    \"\"\"Save model checkpoint with training state\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_loss': train_loss,\n",
        "        'val_loss': val_loss,\n",
        "        'val_acc': val_acc,\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"Checkpoint saved: {filename}\")\n",
        "\n",
        "# 14. Visualization Functions\n",
        "def plot_training_history(train_losses, train_accs, test_losses, test_accs):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(test_losses, label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accs, label='Training Accuracy')\n",
        "    plt.plot(test_accs, label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_prediction_samples(model, test_dataloader, device, class_names):\n",
        "    \"\"\"\n",
        "    Plot sample predictions for each category:\n",
        "    - True Positives (predicted = malignant, actual = malignant)\n",
        "    - False Positives (predicted = malignant, actual = benign)\n",
        "    - True Negatives (predicted = benign, actual = benign)\n",
        "    - False Negatives (predicted = benign, actual = malignant)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store images for each category\n",
        "    true_positives = []  # Predicted malignant, actually malignant\n",
        "    false_positives = [] # Predicted malignant, actually benign\n",
        "    true_negatives = []  # Predicted benign, actually benign\n",
        "    false_negatives = [] # Predicted benign, actually malignant\n",
        "\n",
        "    # Create dictionary to map classes to indices\n",
        "    class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "    # Collect samples for each category\n",
        "    with torch.no_grad():\n",
        "        for images, labels, filenames in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            # Process each image in the batch\n",
        "            for i in range(len(images)):\n",
        "                # Get prediction and ground truth\n",
        "                pred = predicted[i].item()\n",
        "                truth = labels[i].item()\n",
        "\n",
        "                # Denormalize image for display\n",
        "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "                img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "                # Categorize based on prediction vs. truth\n",
        "                sample = (img, filenames[i])\n",
        "\n",
        "                # Malignant is typically index 1, benign is 0\n",
        "                if pred == class_to_idx['malignant'] and truth == class_to_idx['malignant']:\n",
        "                    true_positives.append(sample)\n",
        "                elif pred == class_to_idx['malignant'] and truth == class_to_idx['benign']:\n",
        "                    false_positives.append(sample)\n",
        "                elif pred == class_to_idx['benign'] and truth == class_to_idx['benign']:\n",
        "                    true_negatives.append(sample)\n",
        "                elif pred == class_to_idx['benign'] and truth == class_to_idx['malignant']:\n",
        "                    false_negatives.append(sample)\n",
        "\n",
        "            # Stop once we have enough samples in each category\n",
        "            if (len(true_positives) >= 3 and len(false_positives) >= 3 and\n",
        "                len(true_negatives) >= 3 and len(false_negatives) >= 3):\n",
        "                break\n",
        "\n",
        "    # Function to display samples from a category\n",
        "    def display_category(category_samples, title, max_samples=3):\n",
        "        if not category_samples:\n",
        "            print(f\"No samples found for {title}\")\n",
        "            return\n",
        "\n",
        "        samples_to_show = min(max_samples, len(category_samples))\n",
        "        fig, axes = plt.subplots(1, samples_to_show, figsize=(5*samples_to_show, 5))\n",
        "\n",
        "        # Handle case with only one sample\n",
        "        if samples_to_show == 1:\n",
        "            axes = [axes]\n",
        "\n",
        "        fig.suptitle(title, fontsize=16)\n",
        "\n",
        "        for i in range(samples_to_show):\n",
        "            img, filename = category_samples[i]\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(f\"File: {filename}\")\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Display samples for each category\n",
        "    print(\"\\nSample Predictions:\")\n",
        "\n",
        "    display_category(true_positives, \"True Positives (Predicted: Malignant, Actual: Malignant)\")\n",
        "    display_category(false_positives, \"False Positives (Predicted: Malignant, Actual: Benign)\")\n",
        "    display_category(true_negatives, \"True Negatives (Predicted: Benign, Actual: Benign)\")\n",
        "    display_category(false_negatives, \"False Negatives (Predicted: Benign, Actual: Malignant)\")\n",
        "\n",
        "    # Print summary counts\n",
        "    print(f\"\\nSample counts:\")\n",
        "    print(f\"True Positives (correctly identified malignant): {len(true_positives)}\")\n",
        "    print(f\"False Positives (benign incorrectly classified as malignant): {len(false_positives)}\")\n",
        "    print(f\"True Negatives (correctly identified benign): {len(true_negatives)}\")\n",
        "    print(f\"False Negatives (malignant incorrectly classified as benign): {len(false_negatives)}\")\n",
        "\n",
        "def predict_single_image(model, image_path, device, class_names, apply_preprocessing=True):\n",
        "    \"\"\"\n",
        "    Make prediction on a single image using trained model\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        image_path: Path to image file\n",
        "        device: Computation device (CPU/CUDA)\n",
        "        class_names: List of class names\n",
        "        apply_preprocessing: Whether to apply medical image preprocessing\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with prediction results\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Create preprocessing and transform pipeline similar to dataset class\n",
        "    transform = get_transforms(train=False)\n",
        "\n",
        "    # Apply medical image preprocessing if requested\n",
        "    if apply_preprocessing:\n",
        "        try:\n",
        "            # Convert to numpy for OpenCV processing\n",
        "            np_img = np.array(image)\n",
        "\n",
        "            # Check for valid image dimensions\n",
        "            if np_img.ndim == 3 and np_img.shape[2] == 3:\n",
        "                # Convert to LAB color space\n",
        "                lab = cv2.cvtColor(np_img, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "                # Apply CLAHE to L channel\n",
        "                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "                lab[:,:,0] = clahe.apply(lab[:,:,0])\n",
        "\n",
        "                # Convert back to RGB\n",
        "                enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "                # Apply bilateral filter\n",
        "                enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
        "\n",
        "                # Apply unsharp masking\n",
        "                gaussian = cv2.GaussianBlur(enhanced, (0, 0), 3.0)\n",
        "                enhanced = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)\n",
        "\n",
        "                image = Image.fromarray(enhanced)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during preprocessing: {e}. Using original image.\")\n",
        "\n",
        "    # Apply transforms\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        confidence, predicted_class = torch.max(probabilities, 1)\n",
        "\n",
        "    # Format results\n",
        "    prediction_results = {\n",
        "        'predicted_class': class_names[predicted_class.item()],\n",
        "        'confidence': confidence.item() * 100,  # Convert to percentage\n",
        "        'probabilities': {\n",
        "            class_name: prob.item() * 100\n",
        "            for class_name, prob in zip(class_names, probabilities[0])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return prediction_results\n",
        "\n",
        "# 16. Training Loop\n",
        "def train_model(model, train_dataloader, val_dataloader, num_epochs=30, batch_size=16,\n",
        "                learning_rate=0.0001, weight_decay=0.05, mixup_alpha=0.2,\n",
        "                checkpoint_dir='checkpoints', use_focal_loss=True, device='cuda'):\n",
        "    \"\"\"\n",
        "    Train the model with advanced techniques\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        train_dataloader: DataLoader for training data\n",
        "        val_dataloader: DataLoader for validation data\n",
        "        num_epochs: Number of training epochs\n",
        "        batch_size: Batch size\n",
        "        learning_rate: Base learning rate\n",
        "        weight_decay: Weight decay coefficient\n",
        "        mixup_alpha: Alpha parameter for mixup augmentation (0 to disable)\n",
        "        checkpoint_dir: Directory to save checkpoints\n",
        "        use_focal_loss: Whether to use focal loss\n",
        "        device: Computation device\n",
        "\n",
        "    Returns:\n",
        "        Trained model and training history\n",
        "    \"\"\"\n",
        "    # Create logger\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    log_filename = f'training_log_{timestamp}.log'\n",
        "    logger = setup_logger(log_filename)\n",
        "    logger.info(f\"Starting training with batch size: {batch_size}, lr: {learning_rate}\")\n",
        "\n",
        "    # Create checkpoint directory if it doesn't exist\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize lists to store metrics\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "\n",
        "    # Calculate class weights for loss function\n",
        "    train_labels = torch.cat([y for _, y, _ in train_dataloader])\n",
        "    class_counts = torch.bincount(train_labels)\n",
        "    class_weights = 1.0 / class_counts.float()\n",
        "    class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
        "    class_weights = class_weights.to(device)\n",
        "\n",
        "    # Set up loss function\n",
        "    if use_focal_loss:\n",
        "        criterion = FocalLoss(alpha=class_weights, gamma=2.0, device=device)\n",
        "        logger.info(\"Using Focal Loss with class weights and gamma=2.0\")\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "        logger.info(\"Using Cross Entropy Loss with class weights\")\n",
        "\n",
        "    # Create optimizer with parameter groups\n",
        "    param_groups = get_optimizer_grouped_parameters(model, weight_decay)\n",
        "\n",
        "    # Create optimizer with different learning rates for different parts of the model\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': group['params'], 'lr': learning_rate * group['lr_mult'],\n",
        "         'weight_decay': group['weight_decay']}\n",
        "        for group in param_groups\n",
        "    ])\n",
        "\n",
        "    # Create learning rate scheduler\n",
        "    lr_scheduler = WarmupCosineScheduler(\n",
        "        optimizer,\n",
        "        warmup_epochs=3,\n",
        "        total_epochs=num_epochs,\n",
        "        min_lr_ratio=0.05\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Update learning rate\n",
        "        lr_scheduler.step(epoch)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        logger.info(f\"Epoch {epoch+1}/{num_epochs}, Learning Rate: {current_lr:.6f}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (inputs, targets, _) in enumerate(train_dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Apply mixup augmentation if enabled\n",
        "            if mixup_alpha > 0:\n",
        "                inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, mixup_alpha)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate loss with mixup if enabled\n",
        "            if mixup_alpha > 0:\n",
        "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "            else:\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # For accuracy calculation, we can only do this properly without mixup\n",
        "            if mixup_alpha <= 0:\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Log progress\n",
        "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_dataloader):\n",
        "                logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_dataloader)}], \"\n",
        "                           f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss = running_loss / len(train_dataloader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        if mixup_alpha <= 0:\n",
        "            train_acc = 100. * correct / total\n",
        "            train_accs.append(train_acc)\n",
        "            logger.info(f\"Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
        "        else:\n",
        "            # If using mixup, we can't easily calculate accuracy during training\n",
        "            train_accs.append(0)  # Placeholder\n",
        "            logger.info(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets, _ in val_dataloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # Track metrics\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss = val_loss / len(val_dataloader)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        val_acc = 100. * correct / total\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        logger.info(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Save checkpoint if this is the best model so far\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'best_model_epoch_{epoch+1}.pth')\n",
        "            save_checkpoint(model, optimizer, epoch, train_loss, val_loss, val_acc, checkpoint_path)\n",
        "            logger.info(f\"New best model saved with validation accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Save regular checkpoint every 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
        "            save_checkpoint(model, optimizer, epoch, train_loss, val_loss, val_acc, checkpoint_path)\n",
        "\n",
        "    # Training complete\n",
        "    logger.info(\"Training completed.\")\n",
        "\n",
        "    # Prepare training history\n",
        "    history = {\n",
        "        'train_loss': train_losses,\n",
        "        'train_acc': train_accs,\n",
        "        'val_loss': val_losses,\n",
        "        'val_acc': val_accs\n",
        "    }\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# 17. Evaluation Function\n",
        "def evaluate_model(model, test_dataloader, device, class_names, visualize=True):\n",
        "    \"\"\"\n",
        "    Evaluate model on test data with detailed metrics\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        test_dataloader: DataLoader for test data\n",
        "        device: Computation device\n",
        "        class_names: List of class names\n",
        "        visualize: Whether to visualize results\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with evaluation metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Collect predictions\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets, filenames in test_dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            # Track overall accuracy\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # Store predictions and targets for detailed metrics\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_targets, all_predictions)\n",
        "\n",
        "    # Calculate class-wise metrics\n",
        "    report = classification_report(all_targets, all_predictions,\n",
        "                                  target_names=class_names,\n",
        "                                  output_dict=True)\n",
        "\n",
        "    # Calculate sensitivity and specificity\n",
        "    # For binary classification: malignant is typically positive class (index 1)\n",
        "    if len(class_names) == 2:\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    else:\n",
        "        # For multi-class, we can compute macro-averaged values\n",
        "        sensitivity = np.mean([report[class_name]['recall'] for class_name in class_names])\n",
        "        specificity = 0  # Requires one-vs-rest calculation for multi-class\n",
        "\n",
        "    # Print detailed metrics\n",
        "    print(f\"\\nModel Evaluation on Test Data:\")\n",
        "    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    if len(class_names) == 2:\n",
        "        print(f\"Sensitivity (True Positive Rate): {sensitivity:.4f}\")\n",
        "        print(f\"Specificity (True Negative Rate): {specificity:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    for class_name in class_names:\n",
        "        print(f\"  {class_name}:\")\n",
        "        print(f\"    Precision: {report[class_name]['precision']:.4f}\")\n",
        "        print(f\"    Recall: {report[class_name]['recall']:.4f}\")\n",
        "        print(f\"    F1-Score: {report[class_name]['f1-score']:.4f}\")\n",
        "\n",
        "    # Display confusion matrix\n",
        "    if visualize:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Display sample predictions\n",
        "        plot_prediction_samples(model, test_dataloader, device, class_names)\n",
        "\n",
        "    # Return metrics in a dictionary\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': report,\n",
        "    }\n",
        "\n",
        "    if len(class_names) == 2:\n",
        "        metrics['sensitivity'] = sensitivity\n",
        "        metrics['specificity'] = specificity\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# 18. Grad-CAM Visualization for Explainability\n",
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Implements Grad-CAM for model explainability\n",
        "    \"\"\"\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        # Register hooks\n",
        "        self.register_hooks()\n",
        "\n",
        "    def register_hooks(self):\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations = output\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients = grad_output[0]\n",
        "\n",
        "        # Register the hooks\n",
        "        self.target_layer.register_forward_hook(forward_hook)\n",
        "        self.target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def generate_heatmap(self, input_image, class_idx=None):\n",
        "        \"\"\"\n",
        "        Generate Grad-CAM heatmap\n",
        "\n",
        "        Args:\n",
        "            input_image: Input tensor (1, C, H, W)\n",
        "            class_idx: Target class index. If None, uses the predicted class\n",
        "\n",
        "        Returns:\n",
        "            Heatmap as numpy array\n",
        "        \"\"\"\n",
        "        # Ensure model is in eval mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Get model prediction\n",
        "        output = self.model(input_image)\n",
        "\n",
        "        # If class_idx is None, use the predicted class\n",
        "        if class_idx is None:\n",
        "            _, class_idx = torch.max(output, 1)\n",
        "            class_idx = class_idx.item()\n",
        "\n",
        "        # Zero gradients\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        # Backward pass with the target class\n",
        "        target = torch.zeros_like(output)\n",
        "        target[0, class_idx] = 1\n",
        "        output.backward(gradient=target)\n",
        "\n",
        "        # Get gradients and activations\n",
        "        gradients = self.gradients.detach().cpu()\n",
        "        activations = self.activations.detach().cpu()\n",
        "\n",
        "        # Global average pooling of gradients\n",
        "        weights = torch.mean(gradients, dim=[2, 3], keepdim=True)\n",
        "\n",
        "        # Weighted combination of activation maps\n",
        "        heatmap = torch.sum(weights * activations, dim=1, keepdim=True)\n",
        "\n",
        "        # ReLU on the heatmap\n",
        "        heatmap = F.relu(heatmap)\n",
        "\n",
        "        # Normalize heatmap\n",
        "        heatmap = F.interpolate(heatmap, size=(input_image.size(2), input_image.size(3)),\n",
        "                                mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Min-max normalization\n",
        "        heatmap_min = torch.min(heatmap)\n",
        "        heatmap_max = torch.max(heatmap)\n",
        "        normalized_heatmap = (heatmap - heatmap_min) / (heatmap_max - heatmap_min + 1e-10)\n",
        "\n",
        "        # Convert to numpy\n",
        "        heatmap_np = normalized_heatmap[0, 0].numpy()\n",
        "\n",
        "        return heatmap_np\n",
        "\n",
        "def visualize_heatmap(model, image_path, device, class_names, target_layer=None):\n",
        "    \"\"\"\n",
        "    Visualize Grad-CAM heatmap for a single image\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        image_path: Path to image file\n",
        "        device: Computation device\n",
        "        class_names: List of class names\n",
        "        target_layer: Target layer for Grad-CAM. If None, uses the last layer of CNN backbone\n",
        "\n",
        "    Returns:\n",
        "        Prediction and visualization\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    transform = get_transforms(train=False)\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # If target_layer is not specified, use the last convolutional layer of the CNN backbone\n",
        "    if target_layer is None:\n",
        "        for name, module in model.cnn.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "\n",
        "        # If we haven't found a suitable layer, try to get one from the model directly\n",
        "        if target_layer is None:\n",
        "            print(\"Could not automatically find a suitable target layer. Please specify one.\")\n",
        "            return None\n",
        "\n",
        "    # Create Grad-CAM instance\n",
        "    grad_cam = GradCAM(model, target_layer)\n",
        "\n",
        "    # Get prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        confidence, predicted_class = torch.max(probabilities, 1)\n",
        "\n",
        "    # Generate heatmap for the predicted class\n",
        "    heatmap = grad_cam.generate_heatmap(image_tensor, predicted_class.item())\n",
        "\n",
        "    # Convert image tensor to numpy for visualization\n",
        "    # Denormalize the image\n",
        "    img = image_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    # Create colormap for heatmap\n",
        "    heatmap_colored = plt.cm.jet(heatmap)[:, :, :3]\n",
        "\n",
        "    # Resize heatmap to match image dimensions\n",
        "    heatmap_resized = cv2.resize(heatmap_colored, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Create overlaid image\n",
        "    overlaid = img * 0.7 + heatmap_resized * 0.3\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    axes[1].imshow(heatmap_colored)\n",
        "    axes[1].set_title(\"Grad-CAM Heatmap\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Overlaid image\n",
        "    axes[2].imshow(overlaid)\n",
        "    axes[2].set_title(f\"Prediction: {class_names[predicted_class.item()]} ({confidence.item()*100:.2f}%)\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Return prediction results\n",
        "    prediction_results = {\n",
        "        'predicted_class': class_names[predicted_class.item()],\n",
        "        'confidence': confidence.item() * 100,  # Convert to percentage\n",
        "        'probabilities': {\n",
        "            class_name: prob.item() * 100\n",
        "            for class_name, prob in zip(class_names, probabilities[0])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return prediction_results\n",
        "\n",
        "# 19. Deployment Helper Functions\n",
        "def load_model_from_checkpoint(checkpoint_path, device):\n",
        "    \"\"\"\n",
        "    Load a model from checkpoint\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path: Path to checkpoint file\n",
        "        device: Computation device\n",
        "\n",
        "    Returns:\n",
        "        Loaded model\n",
        "    \"\"\"\n",
        "    # Initialize model\n",
        "    model = ViTCNNEnsemble(num_classes=2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Print info\n",
        "    print(f\"Model loaded from checkpoint: {checkpoint_path}\")\n",
        "    print(f\"Checkpoint was saved at epoch {checkpoint['epoch']+1}\")\n",
        "    print(f\"Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def prepare_model_for_export(model, input_shape=(1, 3, 224, 224)):\n",
        "    \"\"\"\n",
        "    Prepare the model for export to ONNX or TorchScript\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        input_shape: Input tensor shape\n",
        "\n",
        "    Returns:\n",
        "        Model ready for export\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create an example input\n",
        "    dummy_input = torch.randn(input_shape, requires_grad=True)\n",
        "\n",
        "    # Trace the model with JIT\n",
        "    traced_model = torch.jit.trace(model, dummy_input)\n",
        "\n",
        "    return traced_model, dummy_input\n",
        "\n",
        "def export_to_onnx(model, dummy_input, onnx_path):\n",
        "    \"\"\"\n",
        "    Export model to ONNX format\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        dummy_input: Example input tensor\n",
        "        onnx_path: Output path for ONNX file\n",
        "\n",
        "    Returns:\n",
        "        Path to exported model\n",
        "    \"\"\"\n",
        "    # Export the model\n",
        "    torch.onnx.export(\n",
        "        model,                      # model being run\n",
        "        dummy_input,                # model input\n",
        "        onnx_path,                  # where to save the model\n",
        "        export_params=True,         # store the trained parameter weights inside the model file\n",
        "        opset_version=12,           # the ONNX version to export the model to\n",
        "        do_constant_folding=True,   # optimization\n",
        "        input_names=['input'],      # the model's input names\n",
        "        output_names=['output'],    # the model's output names\n",
        "        dynamic_axes={\n",
        "            'input': {0: 'batch_size'},    # variable length axes\n",
        "            'output': {0: 'batch_size'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Model exported to ONNX format: {onnx_path}\")\n",
        "    return onnx_path\n",
        "\n",
        "# 20. Main Execution Function\n",
        "# 20. Main Execution Function\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function to run the training and evaluation pipeline\n",
        "    \"\"\"\n",
        "    # Set random seed for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = BreastCancerDataset(\n",
        "        data_dir='AI_demos/custom_dataset/train',\n",
        "        transform=get_transforms(train=True),\n",
        "        apply_preprocessing=True  # Apply advanced preprocessing\n",
        "    )\n",
        "\n",
        "    val_dataset = BreastCancerDataset(\n",
        "        data_dir='AI_demos/custom_dataset/val',\n",
        "        transform=get_transforms(train=False),\n",
        "        apply_preprocessing=True\n",
        "    )\n",
        "\n",
        "    test_dataset = BreastCancerDataset(\n",
        "        data_dir='AI_demos/custom_dataset/test',\n",
        "        transform=get_transforms(train=False),\n",
        "        apply_preprocessing=True\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=False,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=16,\n",
        "        shuffle=False,\n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    print(\"Initializing model...\")\n",
        "    model = ViTCNNEnsemble(num_classes=len(class_names))\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    trained_model, history = train_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        num_epochs=30,\n",
        "        batch_size=16,\n",
        "        learning_rate=0.0001,\n",
        "        weight_decay=0.05,\n",
        "        mixup_alpha=0.2,\n",
        "        checkpoint_dir='checkpoints',\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(\n",
        "        train_losses=history['train_loss'],\n",
        "        train_accs=history['train_acc'],\n",
        "        test_losses=history['val_loss'],\n",
        "        test_accs=history['val_acc']\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Evaluating model...\")\n",
        "    metrics = evaluate_model(\n",
        "        model=trained_model,\n",
        "        test_dataloader=test_dataloader,\n",
        "        device=device,\n",
        "        class_names=class_names,\n",
        "        visualize=True\n",
        "    )\n",
        "\n",
        "    # Print final results\n",
        "    print(\"\\nFinal Evaluation Results:\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
        "\n",
        "    if len(class_names) == 2:\n",
        "        print(f\"Sensitivity: {metrics['sensitivity']:.4f}\")\n",
        "        print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
        "\n",
        "    # Export model\n",
        "    print(\"Exporting model...\")\n",
        "    traced_model, dummy_input = prepare_model_for_export(trained_model)\n",
        "    export_to_onnx(traced_model, dummy_input, 'breast_cancer_classifier.onnx')\n",
        "\n",
        "    print(\"Pipeline completed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "mAQe1dhDFZfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}